{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9Xx-jP92OgP"
      },
      "source": [
        "# 파이토치(PyTorch)\n",
        "\n",
        "<img src=\"https://img1.daumcdn.net/thumb/R800x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbuUgoV%2FbtqwWZvcHHX%2Fd6XzIFBEfiuFb0UvyV4A50%2Fimg.jpg\" width=\"300\">\n",
        "\n",
        "- 코드 출처: https://pytorch.org/tutorials/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cxreguz2sL0"
      },
      "source": [
        "## 파이토치의 구성요소\n",
        "\n",
        "- `torch`: 텐서를 생성하는 라이브러리\n",
        "\n",
        "- `torch.autograd`: 자동미분 기능을 제공하는 라이브러리\n",
        "\n",
        "- `torch.nn`: 신경망을 생성하는 라이브러리\n",
        "\n",
        "- `torch.multiprocessing`: 병럴처리 기능을 제공하는 라이브러리\n",
        "\n",
        "- `torch.utils`: 데이터 조작 등 유틸리티 기능 제공\n",
        "\n",
        "- `torch.legacy`(./nn/.optim): Torch로부터 포팅해온 코드\n",
        "\n",
        "- `torch.onnx`: ONNX(Open Neural Network Exchange)\n",
        "\n",
        "  - 서로 다른 프레임워크 간의 모델을 공유할 때 사용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gb5O_aSvtHvb"
      },
      "source": [
        "## 텐서(Tensors)\n",
        "- 넘파이(NumPy)의 ndarray와 유사\n",
        "\n",
        "- GPU를 사용한 연산 가속도 가능"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmKIvnx0s8G6"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49IHV-qJE5FI"
      },
      "source": [],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isUHVy-gtZeT"
      },
      "source": [
        "### 초기화 되지 않은 행렬"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PqY3cZatU0D"
      },
      "source": [
        "x = torch.empty(4, 2)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "id": "6ISXpuLR-FWU",
        "outputId": "42329d61-30ac-4590-b868-78a44f5d0c31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-9.3960e-37,  4.3435e-41],\n",
              "        [-1.0486e+38,  3.0850e-41],\n",
              "        [ 0.0000e+00,  0.0000e+00],\n",
              "        [ 0.0000e+00,  0.0000e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPCIJ2pNteZv"
      },
      "source": [
        "### 무작위로 초기화된 행렬"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6oPj2Q9tdYx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c51e6b77-892f-4026-c64a-3308d3afb660"
      },
      "source": [
        "torch.rand(4, 2)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5770, 0.2669],\n",
              "        [0.0078, 0.7064],\n",
              "        [0.8910, 0.2781],\n",
              "        [0.5097, 0.0463]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5aHphIHtiJk"
      },
      "source": [
        "### dtype이 long, 0으로 채워진 텐서"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zykN8aMthXk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f48a80b0-bda7-47be-e578-a721a86815bf"
      },
      "source": [
        "x = torch.zeros(4, 2, dtype=torch.long)\n",
        "x"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 0],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxskTUfGuPUe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "245feaf1-6329-4239-a994-3143daf75d04"
      },
      "source": [
        "torch.tensor([3, 2.3])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3.0000, 2.3000])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.new_ones(2, 4, dtype=torch.double)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nemjc40V-jMh",
        "outputId": "dad91e1e-9f85-4457-fc7c-ab142a96b804"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.randn_like(x, dtype=torch.float)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R36n3Xn--way",
        "outputId": "7ac23ee5-9811-41ee-8a2d-e7a2f75a2a41"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.6821,  0.4338],\n",
              "        [-1.0401, -0.4225],\n",
              "        [-0.7496, -0.7407],\n",
              "        [-0.9910,  0.7802]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7j5sGxGvucpH"
      },
      "source": [
        "### 텐서의 크기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yy-JbqKEuYIR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0967e25e-22d1-47de-8ca3-3200f58a50c5"
      },
      "source": [
        "x.size()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehOg0eDwufru"
      },
      "source": [
        "## 텐서의 연산(operations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8Doc_37uh3G"
      },
      "source": [
        "### 덧셈 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rw4JCYkYuef9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29edafa2-19bc-4233-d349-89a896e2bf29"
      },
      "source": [
        "x"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 0],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        [0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wa44ur1Nuj5U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f61b6e39-4ea5-4dba-fa80-63ea3f20819e"
      },
      "source": [
        "y = torch.rand(4, 2)\n",
        "print(x+y)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4831, 0.5926],\n",
            "        [0.2203, 0.3847],\n",
            "        [0.1389, 0.8385],\n",
            "        [0.3956, 0.5955]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5gcOo-Ouo9B"
      },
      "source": [
        "### 덧셈2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qx-NzJhhumZx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "131af772-f923-43b1-8405-ebe3bff05299"
      },
      "source": [
        "torch.add(x, y)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4831, 0.5926],\n",
              "        [0.2203, 0.3847],\n",
              "        [0.1389, 0.8385],\n",
              "        [0.3956, 0.5955]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlvrQhLuuuIr"
      },
      "source": [
        "### 덧셈3\n",
        "- 결과 텐서를 인자로 제공"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUsLAOTcur1-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f8ce941-90e0-4f70-a715-6e0abdfdc375"
      },
      "source": [
        "result = torch.empty(4, 2)\n",
        "torch.add(x, y, out=result)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4831, 0.5926],\n",
              "        [0.2203, 0.3847],\n",
              "        [0.1389, 0.8385],\n",
              "        [0.3956, 0.5955]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_S51WWF_YAJ",
        "outputId": "bcb32b74-dfa3-45b3-e4c7-49a18dcc809b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4831, 0.5926],\n",
              "        [0.2203, 0.3847],\n",
              "        [0.1389, 0.8385],\n",
              "        [0.3956, 0.5955]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6BdyZFSu2Ei"
      },
      "source": [
        "### 덧셈4\n",
        "- `in-place` 방식\n",
        "\n",
        "- (참고) in-place 방식\n",
        "  - in-place방식으로 텐서의 값을 변경하는 연산 뒤에는 _''가 붙음\n",
        "  - `x.copy_(y), x.t_()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lu8rR4WVu0wQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d06e1b9-1914-4701-a7e1-d72ac2a987bf"
      },
      "source": [
        "print(x)\n",
        "print(y)\n",
        "y.add_(x)\n",
        "print(y)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 0],\n",
            "        [0, 0],\n",
            "        [0, 0],\n",
            "        [0, 0]])\n",
            "tensor([[0.4831, 0.5926],\n",
            "        [0.2203, 0.3847],\n",
            "        [0.1389, 0.8385],\n",
            "        [0.3956, 0.5955]])\n",
            "tensor([[0.4831, 0.5926],\n",
            "        [0.2203, 0.3847],\n",
            "        [0.1389, 0.8385],\n",
            "        [0.3956, 0.5955]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)\n",
        "y.add_(y)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RSq51TP_05C",
        "outputId": "840f5d44-77c4-4756-cdc5-9cfa2193bae9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4831, 0.5926],\n",
            "        [0.2203, 0.3847],\n",
            "        [0.1389, 0.8385],\n",
            "        [0.3956, 0.5955]])\n",
            "tensor([[0.9662, 1.1851],\n",
            "        [0.4405, 0.7695],\n",
            "        [0.2778, 1.6771],\n",
            "        [0.7912, 1.1909]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uo8nsrGjOw6W"
      },
      "source": [
        "### 그 외의 연산\n",
        "- `torch.sub` : 뺄셈\n",
        "\n",
        "- `torch.mul` : 곱셉\n",
        "\n",
        "- `torch.div` : 나눗셈\n",
        "\n",
        "- `torch.mm` : 내적(dot product)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S51kxzPTO1ER"
      },
      "source": [
        "x = torch.Tensor([[1, 3],\n",
        "                  [5, 7]])\n",
        "y = torch.Tensor([[2, 4],\n",
        "                  [6, 8]])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ou0dY8mkPR24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e1375e7-0251-48ad-b26a-8629f13cacda"
      },
      "source": [
        "x-y"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1., -1.],\n",
              "        [-1., -1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RlZZBp3PbE4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4eeb01a9-54f7-446d-8580-3c87143b0d80"
      },
      "source": [
        "torch.sub(x, y)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1., -1.],\n",
              "        [-1., -1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MR-ofE5P7VC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e6c2d73-b7b8-4d12-a968-4fc542421222"
      },
      "source": [
        "x.sub(y)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1., -1.],\n",
              "        [-1., -1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x*y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-wJ6nTyANB0",
        "outputId": "dede6622-e1d7-4148-99b9-571cc5ff50ba"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2., 12.],\n",
              "        [30., 56.]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mul(x, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8h3yphwAM9X",
        "outputId": "52c09194-550c-46f0-d690-4a1dccf0e568"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2., 12.],\n",
              "        [30., 56.]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.mul(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWteYJ-gAM6N",
        "outputId": "f90faa43-1b63-4dbd-afac-0913babd3b8c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2., 12.],\n",
              "        [30., 56.]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.div(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXV02WZPAM26",
        "outputId": "2e1d9a03-7797-4277-83d3-3f81d5c00f8d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5000, 0.7500],\n",
              "        [0.8333, 0.8750]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.mm(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmnCoe5TAMv6",
        "outputId": "b8b34364-ed3f-459c-a26a-9bc67235976d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[20., 28.],\n",
              "        [52., 76.]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8URGwHE_NjDi"
      },
      "source": [
        "## 텐서의 조작(manipulations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCsdZIPTvG53"
      },
      "source": [
        "### 인덱싱\n",
        "- 넘파이처럼 인덱싱 사용가능"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jF2DE8kzvOs3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f24f705f-4255-45ea-a7bd-7171a68f4cf9"
      },
      "source": [
        "x"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 3.],\n",
              "        [5., 7.]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQtBH3r3u7c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b89f7dfe-449d-4314-8f40-fff34de916c4"
      },
      "source": [
        "x[:, 1]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3., 7.])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEscXddKvQ5l"
      },
      "source": [
        "### view\n",
        "- 텐서의 크기(size)나 모양(shape)을 변경"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwhWeqhLvKKj"
      },
      "source": [
        "x = torch.randn(4, 5)\n",
        "y = x.view(20)\n",
        "z = x.view(5, -1)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.size(), y.size(), z.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcWUf7lVArKF",
        "outputId": "a9934712-d1b5-42df-db06-cadda5ac05cb"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 5]) torch.Size([20]) torch.Size([5, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x, y, z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IQFtPV8A3pp",
        "outputId": "95f7b1a5-f89b-4300-f90f-f9b11130929d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 5.3309e-01, -1.1440e+00, -1.1290e+00,  5.9254e-01, -3.9213e-01],\n",
            "        [ 5.5328e-01,  5.1209e-01, -8.0870e-01, -6.2580e-02,  2.0356e+00],\n",
            "        [ 3.9896e-01, -6.8472e-01, -1.0434e+00, -7.7691e-01, -8.4667e-01],\n",
            "        [-6.6549e-01, -9.7533e-01,  1.4123e+00, -8.4015e-05,  8.7223e-01]]) tensor([ 5.3309e-01, -1.1440e+00, -1.1290e+00,  5.9254e-01, -3.9213e-01,\n",
            "         5.5328e-01,  5.1209e-01, -8.0870e-01, -6.2580e-02,  2.0356e+00,\n",
            "         3.9896e-01, -6.8472e-01, -1.0434e+00, -7.7691e-01, -8.4667e-01,\n",
            "        -6.6549e-01, -9.7533e-01,  1.4123e+00, -8.4015e-05,  8.7223e-01]) tensor([[ 5.3309e-01, -1.1440e+00, -1.1290e+00,  5.9254e-01],\n",
            "        [-3.9213e-01,  5.5328e-01,  5.1209e-01, -8.0870e-01],\n",
            "        [-6.2580e-02,  2.0356e+00,  3.9896e-01, -6.8472e-01],\n",
            "        [-1.0434e+00, -7.7691e-01, -8.4667e-01, -6.6549e-01],\n",
            "        [-9.7533e-01,  1.4123e+00, -8.4015e-05,  8.7223e-01]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBY_wuIRvf5j"
      },
      "source": [
        "### item\n",
        "- 텐서에 값이 단 하나라도 존재하면 숫자값을 얻을 수 있음\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0W24QqpvcmV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e9850d3-7635-45da-f929-ad80d8dd584f"
      },
      "source": [
        "x = torch.randn(1)\n",
        "print(x)\n",
        "print(x.item())\n",
        "print(x.dtype)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.3902])\n",
            "-0.39020800590515137\n",
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1sCUVwC3Nua"
      },
      "source": [
        "- 스칼라값 하나만 존재해야함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl4_FAgd3Lt9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "50334ae8-0dbf-43b7-c481-4f01018151f7"
      },
      "source": [
        "x = torch.randn(2)\n",
        "print(x)\n",
        "print(x.item())\n",
        "print(x.dtype)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.7902, -1.0640])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-7c023f92a1c8>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: a Tensor with 2 elements cannot be converted to Scalar"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uThndsy5M6wM"
      },
      "source": [
        "### squeeze\n",
        "- 차원을 축소(제거)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OF3rOavnRxgM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bfc022f-f7d1-4294-ecd6-f5e31a5513c3"
      },
      "source": [
        "tensor = torch.rand(1, 3, 3)\n",
        "print(tensor)\n",
        "tensor.shape"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.8941, 0.9063, 0.0712],\n",
            "         [0.0561, 0.9455, 0.6675],\n",
            "         [0.2822, 0.4245, 0.7720]]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2jq0jHJR5Jw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eef910cb-a2b6-4e18-d352-729bfa46c9c4"
      },
      "source": [
        "t = tensor.squeeze()\n",
        "t"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3885, 0.3508, 0.2627],\n",
              "        [0.5849, 0.3523, 0.9642],\n",
              "        [0.1513, 0.2076, 0.1335]])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COv-dnTYNJ8Z"
      },
      "source": [
        "### unsqueeze\n",
        "- 차원을 증가(생성)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFxaHGY1NOBo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4866e0c3-8055-4e11-cf44-646912cb6db3"
      },
      "source": [
        "tensor = torch.rand(1, 3, 3)\n",
        "print(tensor)\n",
        "print(tensor.shape)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.2821, 0.1807, 0.3948],\n",
            "         [0.9692, 0.6952, 0.7625],\n",
            "         [0.7916, 0.3858, 0.1694]]])\n",
            "torch.Size([1, 3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6sa4tJ7SA8G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be3e072b-0d73-45f3-8ea5-75b486757a7b"
      },
      "source": [
        "t = tensor.unsqueeze(dim=0)\n",
        "print(t)\n",
        "print(t.shape)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[0.2821, 0.1807, 0.3948],\n",
            "          [0.9692, 0.6952, 0.7625],\n",
            "          [0.7916, 0.3858, 0.1694]]]])\n",
            "torch.Size([1, 1, 3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_C_oa9JANOa6"
      },
      "source": [
        "### stack\n",
        "- 텐서간 결합"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3x_XaUYNOuc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f678ca46-d469-4894-c06c-63cf8e99d06d"
      },
      "source": [
        "x = torch.FloatTensor([1, 4])\n",
        "y = torch.FloatTensor([2, 5])\n",
        "z = torch.FloatTensor([3, 6])\n",
        "\n",
        "torch.stack([x, y, z])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 4.],\n",
              "        [2., 5.],\n",
              "        [3., 6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmJscbfg35-c"
      },
      "source": [
        "### cat\n",
        "- 텐서를 결합하는 메소드(concatenate)\n",
        "\n",
        "- 넘파이의 `stack`과 유사하지만, 쌓을 dim이 존재해야함\n",
        "  - 예를 들어, 해당 차원을 늘려준 후 결합\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mv3zlaNm37P1"
      },
      "source": [
        "a = torch.randn(1, 1, 3, 3)\n",
        "b = torch.randn(1, 1, 3, 3)\n",
        "c = torch.cat((a, b), dim=0)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69M5jY60S7Mi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26a3272b-fa08-489a-f5b5-ab2d496fdb3f"
      },
      "source": [
        "c"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[-0.8406,  1.0570, -1.9302],\n",
              "          [-0.9393, -0.4856,  0.7101],\n",
              "          [ 2.2554, -2.3089,  1.0514]]],\n",
              "\n",
              "\n",
              "        [[[ 2.1536,  0.0044,  1.6051],\n",
              "          [-1.4184,  0.9884, -0.3276],\n",
              "          [-1.2999,  1.3322,  1.4259]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eS0H3qJpCmbR",
        "outputId": "0242caf0-5623-4b43-b803-49aa5baf00e8"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn(1, 3, 3)\n",
        "b = torch.randn(1, 3, 3)\n",
        "c = torch.cat((a, b), dim=0)\n",
        "print(c)\n",
        "print(c.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QP8q6UWUCvCS",
        "outputId": "4585703d-3571-4b8e-ba74-a420b0137531"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-1.1231, -1.7599, -0.2218],\n",
            "         [ 0.4823, -0.4349,  0.3466],\n",
            "         [ 0.3039, -0.1464, -0.0402]],\n",
            "\n",
            "        [[ 0.7604, -0.4470,  1.6076],\n",
            "         [ 0.5348,  0.9321, -0.5853],\n",
            "         [ 1.1254, -1.4468,  2.0422]]])\n",
            "torch.Size([2, 3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn(1, 3, 3)\n",
        "b = torch.randn(1, 3, 3)\n",
        "c = torch.cat((a, b), dim=2)\n",
        "print(c)\n",
        "print(c.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fxjRDqUC22q",
        "outputId": "f81b2e8c-a067-42ae-ceaa-8c579e635ad7"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.0196,  0.9802,  0.7931,  0.1568, -1.7531, -0.7615],\n",
            "         [-0.1359, -2.3838, -0.2328, -0.7161, -0.0885, -0.7726],\n",
            "         [-0.7621,  1.1807,  0.4382, -0.1450,  1.0651,  1.7736]]])\n",
            "torch.Size([1, 3, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gGXnOAqQTmG"
      },
      "source": [
        "### chuck\n",
        "- 텐서를 여러 개로 나눌 때 사용\n",
        "\n",
        "- 몇 개의 텐서로 나눌 것이냐"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNV80VzPQZgG"
      },
      "source": [
        "tensor = torch.rand(3, 6)\n",
        "t1, t2, t3 = torch.chunk(tensor, 3, dim=1)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor)\n",
        "print(t1, t2, t3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pv2TVidDEOy",
        "outputId": "7962c2d1-c533-476f-83e3-115f95d18703"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4635, 0.9233, 0.8121, 0.4594, 0.1271, 0.8695],\n",
            "        [0.6006, 0.0519, 0.4840, 0.3780, 0.4507, 0.3338],\n",
            "        [0.3861, 0.2570, 0.3368, 0.8645, 0.0277, 0.6405]])\n",
            "tensor([[0.4635, 0.9233],\n",
            "        [0.6006, 0.0519],\n",
            "        [0.3861, 0.2570]]) tensor([[0.8121, 0.4594],\n",
            "        [0.4840, 0.3780],\n",
            "        [0.3368, 0.8645]]) tensor([[0.1271, 0.8695],\n",
            "        [0.4507, 0.3338],\n",
            "        [0.0277, 0.6405]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U0Qb0jWQgm-"
      },
      "source": [
        "### split\n",
        "- `chunck`와 동일한 기능이지만 조금 다름\n",
        "\n",
        "- 하나의 텐서당 크기가 얼마이냐"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1V6DDnLVQqxz"
      },
      "source": [
        "tensor = torch.rand(3, 6)\n",
        "t1, t2 = torch.split(tensor, 3, dim=1)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor)\n",
        "print(t1)\n",
        "print(t2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khXKMjnqDTRF",
        "outputId": "7f93086d-ccf9-47ed-f49f-62e1dc3d0a5a"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4515, 0.4166, 0.1404, 0.2569, 0.5518, 0.1839],\n",
            "        [0.7322, 0.4235, 0.8748, 0.9431, 0.9496, 0.5232],\n",
            "        [0.0778, 0.6213, 0.0246, 0.0338, 0.8604, 0.2597]])\n",
            "tensor([[0.4515, 0.4166, 0.1404],\n",
            "        [0.7322, 0.4235, 0.8748],\n",
            "        [0.0778, 0.6213, 0.0246]])\n",
            "tensor([[0.2569, 0.5518, 0.1839],\n",
            "        [0.9431, 0.9496, 0.5232],\n",
            "        [0.0338, 0.8604, 0.2597]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "estSwhCgvta6"
      },
      "source": [
        "### torch ↔ numpy\n",
        "- Torch Tensor(텐서)를 Numpy array(배열)로 변환 가능\n",
        "\n",
        "  - `numpy()`\n",
        "  - `from_numpy()`\n",
        "\n",
        "- (참고)\n",
        "  - Tensor가 CPU상에 있다면 Numpy 배열은 메모리 공간을 공유하므로 하나가 변하면, 다른 하나도 변함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxHI7c_yvmAT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "806ae269-b29e-4808-e1f1-9ec570e38829"
      },
      "source": [
        "a = torch.ones(7)\n",
        "a"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1., 1., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whbrhokHwJ3A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6926cc9d-20f4-4070-b664-f3d8e8cf4a02"
      },
      "source": [
        "b = a.numpy()\n",
        "b"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., 1., 1., 1., 1.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5StIhUWDwQjA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bc98dce-f89a-4076-f2fd-65f37bc23505"
      },
      "source": [
        "a.add_(1)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 2., 2., 2., 2., 2., 2.])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RNS5-cRwTt8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dd24a84-a677-47b3-ac93-9098d04cc314"
      },
      "source": [
        "b"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2., 2., 2., 2., 2., 2., 2.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "4_NLj_jsD9Et"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.ones(7)\n",
        "b = torch.from_numpy(a)"
      ],
      "metadata": {
        "id": "j9TbJ7vCEPbj"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yba91zgMEexw",
        "outputId": "8452cc35-d45f-4a06-ba5b-c0527bcc5245"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1., 1., 1., 1.], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.add(a, b, out=a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2ZYc-wNEPzq",
        "outputId": "d272c9aa-647c-4673-e253-ee9b859b9580"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2., 2., 2., 2., 2., 2., 2.])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-8QbSaVEVLf",
        "outputId": "65f94519-fa5d-4382-b246-3d26739db847"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 2., 2., 2., 2., 2., 2.], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-ZaxSvLxEej"
      },
      "source": [
        "## CUDA Tensors\n",
        "- `.to` 메소드를 사용하여 텐서를 어떠한 장치로도 옮길 수 있음\n",
        "  - 예) cpu, gpu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkaQznCRxpUj"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCnC0x2Rxpbk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "173649aa-1d12-4801-9028-acf54a296449"
      },
      "source": [
        "x = torch.randn(1)\n",
        "x"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1814])"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcSsFLkDw-nI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b57c9890-85e3-4cbb-8295-26e16e4e100c"
      },
      "source": [
        "x.item()"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.18135178089141846"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CW0l5kBGEs5K",
        "outputId": "472cab2e-f209-4b01-cda1-830821b66726"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "NRsbPqMOEwaF"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNHWPo3eEwWy",
        "outputId": "4c55978f-9119-46d0-8466-9a016ae7ac1d"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.ones_like(x, device=device)\n",
        "x = x.to(device)\n",
        "z = x+y"
      ],
      "metadata": {
        "id": "_oTasez5EwSy"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7c0xkp4FUcl",
        "outputId": "d9d6678c-054b-4c17-997b-a259d29fdf44"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMbt12utEwLg",
        "outputId": "6db23922-ee44-4e93-84b4-324d56d52ec7"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.1814], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z.to(\"cpu\", torch.double)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVUTyEstEvgO",
        "outputId": "dbfbd5f3-0bf3-40d8-a9da-ddcda4834d60"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.1814], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CNHXorNFF9f",
        "outputId": "c9422248-34c6-4c00-8aa7-06e0614a596a"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.1814], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = x.to(\"cpu\")"
      ],
      "metadata": {
        "id": "jP8CC4BDFeNr"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaqX0p8eFhBE",
        "outputId": "d37a474b-2d8b-43f9-dfcf-f94784b1bb40"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1814])"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.ones_like(x, device=device)\n",
        "x+y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "G8c3qEEIFF1I",
        "outputId": "921e5ce6-b39e-4a44-8271-95d83349ec6e"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-114-1df26d87ba23>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P62Uw95XFFUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKqiGvLWx2nk"
      },
      "source": [
        "## AUTOGRAD (자동미분)\n",
        "- autograd 패키지는 Tensor의 모든 연산에 대해 **자동 미분** 제공\n",
        "\n",
        "- 이는 코드를 어떻게 작성하여 실행하느냐에 따라 역전파가 정의된다는 뜻\n",
        "\n",
        "- backprop를 위한 미분값을 자동으로 계산"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zH41l-MyMHi"
      },
      "source": [
        "### Tensor\n",
        "\n",
        "- data: tensor형태의 데이터\n",
        "\n",
        "- grad: data가 겨쳐온 layer에 대한 미분값 저장\n",
        "\n",
        "- grad_fn: 미분값을 계산한 함수에 대한 정보 저장 (어떤 함수에 대해서 backprop 했는지)\n",
        "\n",
        "- `requires_grad` 속성을 `True`로 설정하면, 해당 텐서에서 이루어지는 모든 연산들을 추적하기 시작\n",
        "\n",
        "- 계산이 완료된 후, `.backward()`를 호출하면 자동으로 `gradient`를 계산할 수 있으며, `.grad` 속성에 누적됨\n",
        "\n",
        "- 기록을 추적하는 것을 중단하게 하려면, `.detach()`를 호출하여 연산기록으로부터 분리\n",
        "\n",
        "- 기록을 추적하는 것을 방지하기 위해 코드 블럭을 `with torch.no_grad():`로 감싸면 `gradient`는 필요없지만, `requires_grad=True`로 설정되어 학습 가능한 매개변수를 갖는 모델을 평가(evaluate)할 때 유용\n",
        "\n",
        "- Autograd 구현에서 매우 중요한 클래스 : `Function` 클래스"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipdk_1jfx47I"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljNU-r9p0Rpo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e14b491b-f81f-4134-a44b-1aba45853c0c"
      },
      "source": [
        "x = torch.ones(3, 3, requires_grad=True)\n",
        "x"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "or6sQ4EB0UYz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc5c2686-ec3b-4014-aac6-61e1675ff972"
      },
      "source": [
        "y = x + 5\n",
        "y"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[6., 6., 6.],\n",
              "        [6., 6., 6.],\n",
              "        [6., 6., 6.]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8NEo0EKHNLQ",
        "outputId": "c3b52e27-323a-4363-c697-88f174cca7df"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<AddBackward0 object at 0x79139962bd90>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuQ7xDmu0Wpj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2976872c-1786-4e22-e10d-b04af4c73ed8"
      },
      "source": [
        "z = y * y * 2\n",
        "out = z.mean()\n",
        "\n",
        "print(z)\n",
        "print(out)"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[72., 72., 72.],\n",
            "        [72., 72., 72.],\n",
            "        [72., 72., 72.]], grad_fn=<MulBackward0>)\n",
            "tensor(72., grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_2iM-Zq0ZdG"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aZ8SWn_0nqt"
      },
      "source": [
        "- `requires_grad_(...)`는 기존 텐서의 `requires_grad`값을 바꿔치기(`in-place`)하여 변경"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHGROgrM0ebO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ae5cf81-638a-4143-98c6-96b159b5cd47"
      },
      "source": [
        "a = torch.randn(3, 3)\n",
        "a = ((a*3)/(a-1))\n",
        "print(a.requires_grad)"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.requires_grad_(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-YeVodZHjwN",
        "outputId": "af9fe696-85c3-454f-ded2-108f8a444d34"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.6016,  0.6185, -6.6495],\n",
              "        [-0.6327,  6.9568, -5.3761],\n",
              "        [ 7.7585,  0.3274, -1.0053]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(a.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBLuadH_HsVU",
        "outputId": "062ffd27-4fe3-4e3e-abe8-f8326df00acb"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = (a*a).sum()\n",
        "print(b.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSHpEGlpHu3z",
        "outputId": "53a41620-8b0e-4470-ae92-7e71c50a7b29"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<SumBackward0 object at 0x79139962bf40>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiEn_stZ1VgU"
      },
      "source": [
        "### 기울기(Gradient)\n",
        "- 역전파: `.backward()`를 통해 역전파 계산 가능"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tdoN9p-1kn4"
      },
      "source": [
        "out.backward()"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CixGTXbV1B9p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "370d9d95-89dd-4ced-99b7-a19802092b5f"
      },
      "source": [
        "out"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(72., grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SY63Mcc-1iNI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f46adb92-64f4-4bfb-af5c-11352b99e40c"
      },
      "source": [
        "print(x.grad)"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2.6667, 2.6667, 2.6667],\n",
            "        [2.6667, 2.6667, 2.6667],\n",
            "        [2.6667, 2.6667, 2.6667]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPaVAbIT3gx_"
      },
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "\n",
        "y = x * 2\n",
        "while y.data.norm() < 1000:\n",
        "    y = y * 2"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SvcsNw8H-nQ",
        "outputId": "76de84ee-38c8-4766-a1ee-6a23cde50a89"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1273.9651,  -126.0527, -1463.3040], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
        "y.backward(v)\n",
        "\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcm_9kqwIDhw",
        "outputId": "fbfc1985-dd8e-4189-9705-02f59dc403d2"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b9amArPXtcX"
      },
      "source": [
        "- `with torch.no_grad()`를 사용하여 gradient의 업데이트를 하지 않음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weeIe5_Z3jVe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd78229c-a50e-49c6-b821-a386ac820ee3"
      },
      "source": [
        "x.requires_grad"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x**2).requires_grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PStHUCTCIYzX",
        "outputId": "aaecf0d6-dae0-4176-97bc-edaaf45b0dfe"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    print((x**2).requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YmfnHaoIbim",
        "outputId": "432800a3-0b1d-495a-8131-404ba9f015d0"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLcTLVRSmCdH"
      },
      "source": [
        "- `detach()`: 내용물(content)은 같지만 require_grad가 다른 새로운 Tensor를 가져올 때"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALcth7Ew3l7H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7167ab25-cc2c-403a-9575-5175f818d794"
      },
      "source": [
        "x.requires_grad"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = x.detach()\n",
        "y.requires_grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJHWan7xIv1R",
        "outputId": "5960f0c8-fa77-401f-c088-067479fd488d"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.eq(y).all()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1SgXkV1Iyyb",
        "outputId": "261593b9-9846-4528-ab71-563acf65f197"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(True)"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y.grad_fn.next_functions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hW8y5yoFI06y",
        "outputId": "51875d38-01e7-4869-dedd-55429926ec38"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "((<MulBackward0 object at 0x79139962a1a0>, 0), (None, 0))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSarysrqBh9D"
      },
      "source": [
        "### 자동 미분 흐름 다시 보기(1)\n",
        "- 계산 흐름  \n",
        "  $a \\rightarrow b  \\rightarrow c  \\rightarrow out $\n",
        "\n",
        "<br>\n",
        "\n",
        "## $\\quad \\frac{\\partial out}{\\partial a} = ?$\n",
        "- `backward()`를 통해  \n",
        "  $a \\leftarrow b  \\leftarrow c  \\leftarrow out $을 계산하면  \n",
        "    $\\frac{\\partial out}{\\partial a}$값이 `a.grad`에 채워짐\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUAc1etP3oBc"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCW7dq9uB89T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0f090e7-a7c8-44e5-e41d-f990a89c10fd"
      },
      "source": [
        "a = torch.ones(2, 2)\n",
        "print(a)"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.ones(2, 2, requires_grad=True)\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NK6cmAv2QWgw",
        "outputId": "3134084b-328d-4611-8c42-7bcf90017e50"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AyyGy49FLz9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a656917f-8a3f-4da9-b63d-8c0bd7145cf6"
      },
      "source": [
        "print(\"a.data:\", a)\n",
        "print(\"a.grad:\", a.grad)\n",
        "print(\"a.grad_fn\", a.grad_fn)"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a.data: tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n",
            "a.grad: None\n",
            "a.grad_fn None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmmJa-hvFPGH"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCwhTsiHGCmG"
      },
      "source": [
        "- $b = a + 2$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUPt042iF9V1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "059e9257-48b2-4541-cd88-87dba57e8220"
      },
      "source": [
        "b = a + 2\n",
        "print(b)"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3., 3.],\n",
            "        [3., 3.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cw2zoq9GHLF"
      },
      "source": [
        "- $c = b^2$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRDS6gP0GFZG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42a67adb-cd92-4986-dc1b-43e64203be7b"
      },
      "source": [
        "c = b**2\n",
        "print(c)"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[9., 9.],\n",
            "        [9., 9.]], grad_fn=<PowBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VynoiUywGSwh"
      },
      "source": [
        "out = c.sum()"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3ryJon9GeMn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dafb03aa-6329-4e1e-e0fc-429b96779373"
      },
      "source": [
        "print(out)"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(36., grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(out)\n",
        "out.backward()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOK3K7x6Qyc_",
        "outputId": "f4ff8585-4ef8-4290-ff56-68bb38a7acf0"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(36., grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5DosBelxQ0-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0aoNsPDHsoG"
      },
      "source": [
        "- a의 `grad_fn`이 None인 이유  \n",
        "  직접적으로 계산한 부분이 없었기 때문"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bccI4vIWGgqj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71aba196-5f74-419c-8f3f-9105a553a21c"
      },
      "source": [
        "print(\"a.data:\", a)\n",
        "print(\"a.grad:\", a.grad)\n",
        "print(\"a.grad_fn\", a.grad_fn)"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a.data: tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n",
            "a.grad: tensor([[6., 6.],\n",
            "        [6., 6.]])\n",
            "a.grad_fn None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oka1mkadHq-N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80cfb2d1-644b-4db8-bef9-6a1341653133"
      },
      "source": [
        "print(\"b.data:\", b)\n",
        "print(\"b.grad:\", b.grad)\n",
        "print(\"b.grad_fn\", b.grad_fn)"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b.data: tensor([[3., 3.],\n",
            "        [3., 3.]], grad_fn=<AddBackward0>)\n",
            "b.grad: None\n",
            "b.grad_fn <AddBackward0 object at 0x791399629db0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-177-dcd2f8a54fcb>:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:486.)\n",
            "  print(\"b.grad:\", b.grad)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiYNajdLccUF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc1a7e69-3c51-4c64-e08a-1bb887701a09"
      },
      "source": [
        "print(\"c.data:\", c)\n",
        "print(\"c.grad:\", c.grad)\n",
        "print(\"c.grad_fn\", c.grad_fn)"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "c.data: tensor([[9., 9.],\n",
            "        [9., 9.]], grad_fn=<PowBackward0>)\n",
            "c.grad: None\n",
            "c.grad_fn <PowBackward0 object at 0x7913996a49a0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-178-0e7142bdf841>:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:486.)\n",
            "  print(\"c.grad:\", c.grad)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcLoMYite0vU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f11ed208-43bb-45c0-83d0-3d4a1132b01c"
      },
      "source": [
        "print(\"out.data:\", out)\n",
        "print(\"out.grad:\", out.grad)\n",
        "print(\"out.grad_fn\", out.grad_fn)"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out.data: tensor(36., grad_fn=<SumBackward0>)\n",
            "out.grad: None\n",
            "out.grad_fn <SumBackward0 object at 0x7913996a4a00>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-179-f41ea53dc7ab>:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:486.)\n",
            "  print(\"out.grad:\", out.grad)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZXgwviHfovj"
      },
      "source": [
        "### 자동 미분 흐름 다시 보기(2)\n",
        "- `grad`값을 넣어서 `backward`\n",
        "\n",
        "- 아래의 코드에서 `.grad`값이 None은 gradient값이 필요하지 않기 때문"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB6DCYXRfcI_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ba65197-40f6-440c-e4d7-1eab967dc59d"
      },
      "source": [
        "x = torch.ones(3, requires_grad=True)\n",
        "y = x**2\n",
        "z = y**2 + x\n",
        "out = z.sum()\n",
        "print(out)"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(6., grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVo-glm8fvFv"
      },
      "source": [
        "grad = torch.Tensor([0.1, 1, 100])\n",
        "z.backward(grad)"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdBklrepf2qq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e99deb4-738d-4ecc-b54b-b623c6603e1a"
      },
      "source": [
        "print(\"x.data:\", x)\n",
        "print(\"x.grad:\", x.grad)\n",
        "print(\"x.grad_fn\", x.grad_fn)"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.data: tensor([1., 1., 1.], requires_grad=True)\n",
            "x.grad: tensor([  0.5000,   5.0000, 500.0000])\n",
            "x.grad_fn None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQvUGlfRf7jU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29cd6b78-e157-44c3-c08d-e1b2b03c41e2"
      },
      "source": [
        "print(\"y.data:\", y)\n",
        "print(\"y.grad:\", y.grad)\n",
        "print(\"y.grad_fn\", y.grad_fn)"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y.data: tensor([1., 1., 1.], grad_fn=<PowBackward0>)\n",
            "y.grad: None\n",
            "y.grad_fn <PowBackward0 object at 0x7913a2c9f5b0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-185-0c4fd7c1ff45>:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:486.)\n",
            "  print(\"y.grad:\", y.grad)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7TFHdMfgxvW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5a7fde3-9b4f-41bb-e7bf-1149b1f5786e"
      },
      "source": [
        "print(\"z.data:\", z)\n",
        "print(\"z.grad:\", z.grad)\n",
        "print(\"z.grad_fn\", z.grad_fn)"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "z.data: tensor([2., 2., 2.], grad_fn=<AddBackward0>)\n",
            "z.grad: None\n",
            "z.grad_fn <AddBackward0 object at 0x7913996641c0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-186-7a3fc72eb1c6>:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:486.)\n",
            "  print(\"z.grad:\", z.grad)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"out.data:\", out)\n",
        "print(\"out.grad:\", out.grad)\n",
        "print(\"out.grad_fn\", out.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lE2Ch5-fSQC8",
        "outputId": "49a12d15-1e2c-43c9-857e-163cc6321632"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out.data: tensor(6., grad_fn=<SumBackward0>)\n",
            "out.grad: None\n",
            "out.grad_fn <SumBackward0 object at 0x791399665ae0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-187-f41ea53dc7ab>:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:486.)\n",
            "  print(\"out.grad:\", out.grad)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKv-osmNmWiA"
      },
      "source": [
        "## nn & nn.functional\n",
        "\n",
        "- 두 패키지가 같은 기능이지만 방식이 조금 다름\n",
        "\n",
        "- 위의 `autograd` 관련 작업들을 두 패키지를 통해 진행할 수 있음\n",
        "\n",
        "- 텐서를 직접 다룰 때 `requires_grad`와 같은 방식으로 진행할 수 있음\n",
        "\n",
        "- 결론적으로, `torch.nn`은 attribute를 활용해 state를 저장하고 활용하고,  \n",
        "  `torch.nn.functional`로 구현한 함수의 경우에는 인스턴스화 시킬 필요 없이 사용이 가능\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk8fkKq3nWP1"
      },
      "source": [
        "### nn 패키지\n",
        "\n",
        "- 주로 가중치(weights), 편향(bias)값들이 내부에서 자동으로 생성되는 레이어들을 사용할 때  \n",
        "  - 따라서, `weight`값들을 직접 선언 안함\n",
        "\n",
        "- 예시\n",
        "  - Containers\n",
        "\n",
        "  - Convolution Layers\n",
        "\n",
        "  - Pooling layers\n",
        "\n",
        "  - Padding Layers\n",
        "\n",
        "  - Non-linear Activations (weighted sum, nonlinearity)\n",
        "\n",
        "  - Non-linear Activations (other)\n",
        "\n",
        "  - Normalization Layers\n",
        "\n",
        "  - Recurrent Layers\n",
        "\n",
        "  - Transformer Layers\n",
        "\n",
        "  - Linear Layers\n",
        "\n",
        "  - Dropout Layers\n",
        "\n",
        "  - Sparse Layers\n",
        "\n",
        "  - Distance Functions\n",
        "\n",
        "  - Loss Functions\n",
        "\n",
        "  - ..\n",
        "- https://pytorch.org/docs/stable/nn.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tEtWHAsmZMy"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn.Conv2d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Inqx9z-TS2dc",
        "outputId": "5d759785-1773-4b98-c110-b0a37cacf60c"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.nn.modules.conv.Conv2d"
            ]
          },
          "metadata": {},
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcjCbeEQqPSI"
      },
      "source": [
        "- Convolution Layer 예시 (1)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ7Y0tCOpkhM"
      },
      "source": [
        "m = nn.Conv2d(16, 33, 3, stride=2)\n",
        "m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\n",
        "m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))\n",
        "\n",
        "input = torch.randn(20, 16, 50, 100)\n",
        "output = m(input)"
      ],
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLqGbclbp3_N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cce4ed02-61f2-4a2b-c7fb-b0f10bbf7eb1"
      },
      "source": [
        "output.shape"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20, 33, 26, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYeGAJEuneqW"
      },
      "source": [
        "### nn.functional 패키지\n",
        "\n",
        "- 가중치를 직접 선언하여 인자로 넣어줘야함\n",
        "\n",
        "- 예시)\n",
        "  - Convolution functions\n",
        "\n",
        "  - Pooling functions\n",
        "  \n",
        "  - Non-linear activation functions\n",
        "\n",
        "  - Normalization functions\n",
        "\n",
        "  - Linear functions\n",
        "\n",
        "  - Dropout functions\n",
        "  \n",
        "  - Sparse functions\n",
        "  \n",
        "  - Distance functions\n",
        "\n",
        "  - Loss functions\n",
        "  - ..\n",
        "\n",
        "- https://pytorch.org/docs/stable/nn.functional.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpwbO9Dhpflm"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUYaJ5aLqKed"
      },
      "source": [
        "- Convolution Layer 예시 (2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAWLQE2GouHP"
      },
      "source": [
        "filters = torch.randn(8, 4, 3, 3)"
      ],
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.randn(1, 4, 5, 5)\n",
        "conv = F.conv2d(inputs, filters, padding=1)\n",
        "conv.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLkQiGyrT55y",
        "outputId": "4c9c80f2-3b03-4985-c943-ab1c16866ddb"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 5, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWmSlFBrpms1"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wah4RsmgrRDP"
      },
      "source": [
        "## Torchvision\n",
        "\n",
        "- `transforms`: 전처리할 때 사용하는 메소드\n",
        "\n",
        "- `transforms`에서 제공하는 클래스 이외에  \n",
        "  일반적으로 클래스를 따로 만들어 전처리 단계를 진행\n",
        "  \n",
        "  - 아래의 코드에서 다양한 전처리 기술 확인  \n",
        "    https://pytorch.org/docs/stable/torchvision/transforms.html\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akvq4QWmqSil"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKu5mzyTs-Qj"
      },
      "source": [
        "- 예시)\n",
        "  - `DataLoader`의 인자로 들어갈 `transform`을 미리 정의할 수 있음\n",
        "\n",
        "  - `Compose`를 통해 리스트 안에 순서대로 전처리 진행\n",
        "\n",
        "  - 대표적인 예로, `ToTensor`()를 하는 이유는  \n",
        "   <u>torchvision이 PIL Image형태로만 입력을 받기 때문에</u> 데이터 처리를 위해서 Tensor형으로 변환해야함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6K7FH-Rs9my"
      },
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
        "                                ])"
      ],
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4l1GvIlslKa"
      },
      "source": [
        "## utils.data\n",
        "\n",
        "- `Dataset`에는 다양한 데이터셋이 존재  \n",
        "  - MNIST, CIFAR10, ...\n",
        "\n",
        "- `DataLoader`, `Dataset`을 통해  \n",
        "  `batch_size`, `train`여부, `transform`등을 인자로 넣어 데이터를 어떻게 load할 것인지 정해줄 수 있음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wsZKY7-s2Vv"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lldpI2lquBu3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8861a668-8314-4ab4-d054-0e632f48271b"
      },
      "source": [
        "trainset = torchvision.datasets.MNIST(root='/content/', train=True, download=True, transform=transform)"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /content/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 111821581.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/MNIST/raw/train-images-idx3-ubyte.gz to /content/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /content/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 24853445.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/MNIST/raw/train-labels-idx1-ubyte.gz to /content/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /content/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 33225038.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/MNIST/raw/t10k-images-idx3-ubyte.gz to /content/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /content/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 20617455.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/MNIST/raw/t10k-labels-idx1-ubyte.gz to /content/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKddZnT1uQmT"
      },
      "source": [
        "testset = torchvision.datasets.MNIST(root='/content/', train=False, download=True, transform=transform)"
      ],
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(trainset, batch_size=8, shuffle=True, num_workers=1)\n",
        "test_loader = DataLoader(testset, batch_size=8, shuffle=False, num_workers=1)"
      ],
      "metadata": {
        "id": "55d__qsLVxIl"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrxymquLxeo8"
      },
      "source": [
        "- `batch_size`만큼 데이터를 하나씩 가져옴"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = next(iter(train_loader))"
      ],
      "metadata": {
        "id": "s7KRpm-EVoq8"
      },
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images.shape, labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIfI_6iCVsvS",
        "outputId": "279fea2e-53a2-4bf6-938c-3b6b9d243061"
      },
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([8, 1, 28, 28]), torch.Size([8]))"
            ]
          },
          "metadata": {},
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPUC0a0aw6OM"
      },
      "source": [
        "<u>**(중요) torch에서는 channel(채널)이 앞에 옴**</u>\n",
        "\n",
        "- `channel first`\n",
        "\n",
        "- tensorflow, keras 등에서는 channel이 뒤에 옴(`channel last`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuhylD3iyFYr"
      },
      "source": [
        "### 데이터 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9hAQmQlul8P"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDcUY6o4xUQp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ab5948b-201d-4599-caff-9d2c6515d219"
      },
      "source": [
        "torch_image = torch.squeeze(images[0])\n",
        "torch_image.shape"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZmPWiGbxoiW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70db2345-5325-433d-e252-e65e8f11381a"
      },
      "source": [
        "labels[0]"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5)"
            ]
          },
          "metadata": {},
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUOdd4UaxaXO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "f8604cce-823f-41c8-8bb7-b0801a3173c5"
      },
      "source": [
        "plt.title(labels[0])\n",
        "plt.imshow(torch_image)"
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x791369d763e0>"
            ]
          },
          "metadata": {},
          "execution_count": 230
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDQfjw4wxr1z"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDCVw59ax3-A"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVcWQlxzihtS"
      },
      "source": [
        "## 각 Layer 설명"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGXn1_weif5H"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73kJ3heBi26y"
      },
      "source": [
        "### nn.Conv2d\n",
        "\n",
        "- `in_channels`: channel의 갯수\n",
        "\n",
        "- `out_channels`: 출력 채널의 갯수\n",
        "\n",
        "- `kernel_size`: 커널(필터) 사이즈\n",
        "\n",
        "- 텐서플로우, 케라스와 다르게 레이어의 `input`인자에도 값을 집어 넣어줘야함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcHJguyFipTl"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWiJbViHjFG0"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxWYFm2xjUeN"
      },
      "source": [
        "- `wegiht`확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "za0enRbyjPzV"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAZcTU2gjiCX"
      },
      "source": [
        "- `weight`는 `detach()`를 통해 꺼내줘야 `numpy()`변환이 가능"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eN_oUBkjT85"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwso9tsijmz8"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUegf6HPjdPl"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMeTOqVmcdWa"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvolnNsscdHs"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLOAfD5mjup1"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r50wFkl6j1sY"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiIp-frJj2Hl"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOHMu-UQkW3a"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sCqGmH_kwHm"
      },
      "source": [
        "### Pooling\n",
        "- `F.max_pool2d`\n",
        "  - `stride`\n",
        "\n",
        "  - `kernel_size`\n",
        "\n",
        "- `torch.nn.MaxPool2d` 도 많이 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYqPrLH1kxQl"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvI8W_8Yk81S"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV3HK4FulCaJ"
      },
      "source": [
        "- MaxPool Layer는 weight가 없기 때문에 바로 `numpy()`변환 가능"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fseB_qlflBta"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6w8DQnNtlNCq"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7RVioKwlbH1"
      },
      "source": [
        "### Linear\n",
        "- 1d만 가능 `.view()`를 통해 1D로 펼쳐줘야함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kwcedadrlcbl"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mYQy4I3lmAm"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wgSmY0Zlofk"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcJFqf0alsxr"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewEpebSVluHz"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IjPKDKRl3CV"
      },
      "source": [
        "### Softmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obhBb3O-lzbs"
      },
      "source": [
        "with torch.no_grad():\n",
        "    flatten = torch_image.view(1, 28*28)\n",
        "    lin = nn.Linear(784, 10)(flatten)\n",
        "    softmax = F.softmax(lin, dim=1)"
      ],
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljgOEyNMmBEE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3002873-c566-4235-d8d4-7722b9b2d22e"
      },
      "source": [
        "softmax"
      ],
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0483, 0.2110, 0.1323, 0.0362, 0.2256, 0.0493, 0.0608, 0.0341, 0.1153,\n",
              "         0.0871]])"
            ]
          },
          "metadata": {},
          "execution_count": 233
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.sum(softmax)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "IJSyNP0HW_Jd",
        "outputId": "a546f006-6621-4435-f3de-bb09f64efabd"
      },
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-235-4d24c12cbb06>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2296\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2298\u001b[0;31m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0m\u001b[1;32m   2299\u001b[0m                           initial=initial, where=where)\n\u001b[1;32m   2300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: sum() received an invalid combination of arguments - got (out=NoneType, axis=NoneType, ), but expected one of:\n * (*, torch.dtype dtype)\n      didn't match because some of the keywords were incorrect: out, axis\n * (tuple of ints dim, bool keepdim, *, torch.dtype dtype)\n * (tuple of names dim, bool keepdim, *, torch.dtype dtype)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18ymFSRAmBo7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "432f0b45-f9ba-4934-ff40-50425e24e540"
      },
      "source": [
        "np.sum(softmax.numpy())"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYh13Bnj5wEN"
      },
      "source": [
        "### F.relu\n",
        "\n",
        "- ReLU 함수를 적용하는 레이어\n",
        "\n",
        "- `nn.ReLU`로도 사용 가능"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4VFePpR9_Ak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0f42fbd-a408-48a8-e9ea-cb6268072f69"
      },
      "source": [
        "inputs = torch.randn(4, 3, 28, 28).to(device)\n",
        "inputs.shape"
      ],
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 3, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 236
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lKlSiaY5wZW"
      },
      "source": [
        "layer = nn.Conv2d(3, 20, 5, 1).to(device)\n",
        "output = F.relu(layer(inputs))\n",
        "output.shape"
      ],
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bn1OL02RXLWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yuABl4h-yye"
      },
      "source": [
        "## Optimizer\n",
        "\n",
        "- `import torch.optim as optim`\n",
        "\n",
        "- `model`의 파라미터를 업데이트\n",
        "\n",
        "- 예시)\n",
        "  ```python\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "  optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "  ```\n",
        "\n",
        "- `.zero_grad()`로 초기화\n",
        "- `.step()`으로 업데이트\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AIbNkQ--XQoW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}